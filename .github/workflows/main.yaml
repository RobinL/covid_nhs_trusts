# Hourly scraping

name: update_nhs_data

# Controls when the action will run. Triggers the workflow on push or pull request
# events but only for the master branch
on:
  push:
  schedule:
    - cron: '0 19 * * *'
  
    
# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # Scraping job
  autoscrape:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Load repo and install R
    steps:
    - uses: actions/checkout@master
    
    - name: Set up Python version
      uses: actions/setup-python@v2
      with:
        python-version: '3.7' 

    # Set-up Python
    - name: Install pacakges
      run: |
        pip install requests
        pip install selenium
        pip install pandas 
        pip install pyarrow
        pip install altair 
        pip install altair_saver
        pip install xlrd
        pip install beautifulsoup4

    # Run R script
    - name: Scrape
      run: python create_data.py
    
    # Add new files in data folder, commit along with other modified files, push
    - name: Commit files
      run: |
        git config --local user.name github-actions
        git config --local user.email "actions@github.com"
        git add *.png
        git add *.csv
        git add *.parquet
        git commit -am "GH ACTION Headlines $(date)"
        git push origin master
      env:
        REPO_KEY: ${{secrets.GITHUB_TOKEN}}
        username: github-actions
